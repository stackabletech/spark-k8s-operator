= Installation

There are three ways to run the Spark Operator:

1. Helm managed Docker container deployment on Kubernetes

2. As a Docker container

3. Build from source.

== Helm

Helm allows you to download and deploy Stackable operators on Kubernetes and is by far the easiest
installation method. First ensure that you have installed the Stackable Operators Helm repository:
[source,bash]
----
$ helm repo add stackable https://repo.stackable.tech/repository/helm-stable/
----

Then install the Stackable Operator for Apache Spark
[source,bash]
----
$ helm install spark-operator stackable/spark-operator
----

Helm will deploy the operator in a Kubernetes container and apply the CRDs for the Apache Spark
service. You are now ready to deploy Apache Spark in Kubernetes.

== Docker

This Operator is published as a Docker image:

[source]
----
docker.stackable.tech/stackable/spark-operator
----

When installing manually with Docker you will need to install the Stackable CRDs for Apache Spark
in your Kubernetes environment. These are available on the
https://github.com/stackabletech/spark-operator/tree/main/deploy/crd[Stackable GitHub repository]
for this operator.
[source]
----
$ kubectl apply -f SparkApplication.crd.yaml
----

To run it straight from Docker you can use this command:
[source,bash]
----
docker run \
    --name spark-operator \
    --network host \
    --env KUBECONFIG=/home/stackable/.kube/config \
    --mount type=bind,source="$HOME/.kube/config",target="/home/stackable/.kube/config" \
    docker.stackable.tech/stackable/spark-operator:latest
----

== Building the operator from source

This operator is written in Rust and is developed against the latest stable Rust release (1.57 at
the time of writing).

[source]
----
cargo run -- crd | kubectl apply -f -
cargo run -- run
----

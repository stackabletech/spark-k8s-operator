---
apiVersion: spark.stackable.tech/v1alpha1
kind: SparkApplication
metadata:
  name: pyspark-ny-public-s3-image
spec:
  version: "1.0"
  # everything under /jobs will be copied to /stackable/spark/jobs
  image:
    custom: docker.stackable.tech/stackable/ny-tlc-report:{{ test_scenario['values']['ny-tlc-report'] }}
    productVersion: {{ test_scenario['values']['ny-tlc-report'] }}
  sparkImage:
    custom: docker.stackable.tech/stackable/pyspark-k8s:{{ test_scenario['values']['spark'] }}-stackable{{ test_scenario['values']['stackable'] }}
    productVersion: {{ test_scenario['values']['spark'] }}
    pullPolicy: IfNotPresent
  mode: cluster
  mainApplicationFile: local:///stackable/spark/jobs/ny_tlc_report.py
  args:
    - "--input 's3a://my-bucket/yellow_tripdata_2021-07.csv'"
  deps:
    requirements:
      - tabulate==0.8.9
  s3bucket:
    inline:
      bucketName: my-bucket
      connection:
        inline:
          host: test-minio
          port: 9000
          accessStyle: Path
  sparkConf:
    spark.hadoop.fs.s3a.aws.credentials.provider: "org.apache.hadoop.fs.s3a.AnonymousAWSCredentialsProvider"
  executor:
    instances: 3

---
role: Aggregator
service:
  ports:
  - name: api
    port: 8686
    protocol: TCP
    targetPort: 8686
  - name: vector
    port: 6123
    protocol: TCP
    targetPort: 6000
customConfig:
  api:
    address: 0.0.0.0:8686
    enabled: true
  sources:
    vector:
      address: 0.0.0.0:6000
      type: vector
      version: "2"
  transforms:

    # SparkHistoryServer spark-history

    filteredSparkHistoryAutomaticLogConfigSparkHistory:
      type: filter
      inputs: [vector]
      condition: >-
        .pod == "spark-history-node-automatic-log-config-0" &&
        .container == "spark-history"
    filteredSparkHistoryAutomaticLogConfigVector:
      type: filter
      inputs: [vector]
      condition: >-
        .pod == "spark-history-node-automatic-log-config-0" &&
        .container == "vector"
    filteredSparkHistoryCustomLogConfigSparkHistory:
      type: filter
      inputs: [vector]
      condition: >-
        .pod == "spark-history-node-custom-log-config-0" &&
        .container == "spark-history"
    filteredSparkHistoryCustomLogConfigVector:
      type: filter
      inputs: [vector]
      condition: >-
        .pod == "spark-history-node-custom-log-config-0" &&
        .container == "vector"

    # SparkApplication spark-automatic-log-config

    filteredSparkAutomaticLogConfigSubmitSpark:
      type: filter
      inputs: [vector]
      condition: >-
        match(string!(.pod), r'^spark-automatic-log-config-[^-]+$') &&
        .container == "spark-submit"
    filteredSparkAutomaticLogConfigSubmitVector:
      type: filter
      inputs: [vector]
      condition: >-
        match(string!(.pod), r'^spark-automatic-log-config-[^-]+$') &&
        .container == "vector"
    filteredSparkAutomaticLogConfigDriverSpark:
      type: filter
      inputs: [vector]
      condition: >-
        .cluster == "spark-automatic-log-config" &&
        ends_with(string!(.pod), "-driver") &&
        .container == "spark"
    filteredSparkAutomaticLogConfigDriverJob:
      type: filter
      inputs: [vector]
      condition: >-
        .cluster == "spark-automatic-log-config" &&
        ends_with(string!(.pod), "-driver") &&
        .container == "job"
    filteredSparkAutomaticLogConfigDriverVector:
      type: filter
      inputs: [vector]
      condition: >-
        .cluster == "spark-automatic-log-config" &&
        ends_with(string!(.pod), "-driver") &&
        .container == "vector"
    filteredSparkAutomaticLogConfigExecutorSpark:
      type: filter
      inputs: [vector]
      condition: >-
        .cluster == "spark-automatic-log-config" &&
        ends_with(string!(.pod), "-exec-1") &&
        .container == "spark"
    filteredSparkAutomaticLogConfigExecutorJob:
      type: filter
      inputs: [vector]
      condition: >-
        .cluster == "spark-automatic-log-config" &&
        ends_with(string!(.pod), "-exec-1") &&
        .container == "job"
    filteredSparkAutomaticLogConfigExecutorVector:
      type: filter
      inputs: [vector]
      condition: >-
        .cluster == "spark-automatic-log-config" &&
        ends_with(string!(.pod), "-exec-1") &&
        .container == "vector"

    # SparkApplication spark-custom-log-config

    filteredSparkCustomLogConfigSubmitSpark:
      type: filter
      inputs: [vector]
      condition: >-
        match(string!(.pod), r'^spark-custom-log-config-[^-]+$') &&
        .container == "spark-submit"
    filteredSparkCustomLogConfigSubmitVector:
      type: filter
      inputs: [vector]
      condition: >-
        match(string!(.pod), r'^spark-custom-log-config-[^-]+$') &&
        .container == "vector"
    filteredSparkCustomLogConfigDriverSpark:
      type: filter
      inputs: [vector]
      condition: >-
        .cluster == "spark-custom-log-config" &&
        ends_with(string!(.pod), "-driver") &&
        .container == "spark"
    filteredSparkCustomLogConfigDriverJob:
      type: filter
      inputs: [vector]
      condition: >-
        .cluster == "spark-custom-log-config" &&
        ends_with(string!(.pod), "-driver") &&
        .container == "job"
    filteredSparkCustomLogConfigDriverVector:
      type: filter
      inputs: [vector]
      condition: >-
        .cluster == "spark-custom-log-config" &&
        ends_with(string!(.pod), "-driver") &&
        .container == "vector"
    filteredSparkCustomLogConfigExecutorSpark:
      type: filter
      inputs: [vector]
      condition: >-
        .cluster == "spark-custom-log-config" &&
        ends_with(string!(.pod), "-exec-1") &&
        .container == "spark"
    filteredSparkCustomLogConfigExecutorJob:
      type: filter
      inputs: [vector]
      condition: >-
        .cluster == "spark-custom-log-config" &&
        ends_with(string!(.pod), "-exec-1") &&
        .container == "job"
    filteredSparkCustomLogConfigExecutorVector:
      type: filter
      inputs: [vector]
      condition: >-
        .cluster == "spark-custom-log-config" &&
        ends_with(string!(.pod), "-exec-1") &&
        .container == "vector"

    # SparkApplication pyspark-automatic-log-config

    filteredPysparkAutomaticLogConfigSubmitSpark:
      type: filter
      inputs: [vector]
      condition: >-
        match(string!(.pod), r'^pyspark-automatic-log-config-[^-]+$') &&
        .container == "spark-submit"
    filteredPysparkAutomaticLogConfigSubmitVector:
      type: filter
      inputs: [vector]
      condition: >-
        match(string!(.pod), r'^pyspark-automatic-log-config-[^-]+$') &&
        .container == "vector"
    filteredPysparkAutomaticLogConfigDriverSpark:
      type: filter
      inputs: [vector]
      condition: >-
        .cluster == "pyspark-automatic-log-config" &&
        ends_with(string!(.pod), "-driver") &&
        .container == "spark"
    filteredPysparkAutomaticLogConfigDriverRequirements:
      type: filter
      inputs: [vector]
      condition: >-
        .cluster == "pyspark-automatic-log-config" &&
        ends_with(string!(.pod), "-driver") &&
        .container == "requirements"
    filteredPysparkAutomaticLogConfigDriverVector:
      type: filter
      inputs: [vector]
      condition: >-
        .cluster == "pyspark-automatic-log-config" &&
        ends_with(string!(.pod), "-driver") &&
        .container == "vector"
    filteredPysparkAutomaticLogConfigExecutorSpark:
      type: filter
      inputs: [vector]
      condition: >-
        .cluster == "pyspark-automatic-log-config" &&
        ends_with(string!(.pod), "-exec-1") &&
        .container == "spark"
    filteredPysparkAutomaticLogConfigExecutorRequirements:
      type: filter
      inputs: [vector]
      condition: >-
        .cluster == "pyspark-automatic-log-config" &&
        ends_with(string!(.pod), "-exec-1") &&
        .container == "requirements"
    filteredPysparkAutomaticLogConfigExecutorVector:
      type: filter
      inputs: [vector]
      condition: >-
        .cluster == "pyspark-automatic-log-config" &&
        ends_with(string!(.pod), "-exec-1") &&
        .container == "vector"

    # SparkApplication pyspark-custom-log-config

    filteredPysparkCustomLogConfigSubmitSpark:
      type: filter
      inputs: [vector]
      condition: >-
        match(string!(.pod), r'^pyspark-custom-log-config-[^-]+$') &&
        .container == "spark-submit"
    filteredPysparkCustomLogConfigSubmitVector:
      type: filter
      inputs: [vector]
      condition: >-
        match(string!(.pod), r'^pyspark-custom-log-config-[^-]+$') &&
        .container == "vector"
    filteredPysparkCustomLogConfigDriverSpark:
      type: filter
      inputs: [vector]
      condition: >-
        .cluster == "pyspark-custom-log-config" &&
        ends_with(string!(.pod), "-driver") &&
        .container == "spark"
    filteredPysparkCustomLogConfigDriverRequirements:
      type: filter
      inputs: [vector]
      condition: >-
        .cluster == "pyspark-custom-log-config" &&
        ends_with(string!(.pod), "-driver") &&
        .container == "requirements"
    filteredPysparkCustomLogConfigDriverVector:
      type: filter
      inputs: [vector]
      condition: >-
        .cluster == "pyspark-custom-log-config" &&
        ends_with(string!(.pod), "-driver") &&
        .container == "vector"
    filteredPysparkCustomLogConfigExecutorSpark:
      type: filter
      inputs: [vector]
      condition: >-
        .cluster == "pyspark-custom-log-config" &&
        ends_with(string!(.pod), "-exec-1") &&
        .container == "spark"
    filteredPysparkCustomLogConfigExecutorRequirements:
      type: filter
      inputs: [vector]
      condition: >-
        .cluster == "pyspark-custom-log-config" &&
        ends_with(string!(.pod), "-exec-1") &&
        .container == "requirements"
    filteredPysparkCustomLogConfigExecutorVector:
      type: filter
      inputs: [vector]
      condition: >-
        .cluster == "pyspark-custom-log-config" &&
        ends_with(string!(.pod), "-exec-1") &&
        .container == "vector"
  sinks:
    out:
      inputs: [filtered*]
{% if lookup('env', 'VECTOR_AGGREGATOR') %}
      type: vector
      address: {{ lookup('env', 'VECTOR_AGGREGATOR') }}
      buffer:
        when_full: drop_newest
{% else %}
      type: blackhole
{% endif %}

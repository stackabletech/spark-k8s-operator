= Installation
:description: Learn how to set up Spark with the Stackable Operator, from installation to running your first job, including prerequisites and resource recommendations.

Install the Stackable Spark operator as well as the commons, secret and listener operators
which are required by all Stackable operators.

== Dependencies

Spark applications almost always require dependencies like database drivers, REST api clients and many others.
These dependencies must be available on the `classpath` of each executor (and in some cases of the driver, too).
There are multiple ways to provision Spark jobs with such dependencies: some are built into Spark itself while others are implemented at the operator level.
In this guide we are going to keep things simple and look at executing a Spark job that has a minimum of dependencies.

More information about the different ways to define Spark jobs and their dependencies is given on the following pages:

* xref:usage-guide/index.adoc[]
* xref:job_dependencies.adoc[]

== Stackable Operators

There are multiple ways to install the Stackable Operator for Apache Spark.
xref:management:stackablectl:index.adoc[] is the preferred way, but Helm is also supported.
OpenShift users may prefer installing the operator from the RedHat Certified Operator catalog using the OpenShift web console.

[tabs]
====
stackablectl::
+
--
`stackablectl` is the command line tool to interact with Stackable operators and our recommended way to install operators.
Follow the xref:management:stackablectl:installation.adoc[installation steps] for your platform.

After you have installed `stackablectl` run the following command to install the Spark operator:

[source,bash]
----
include::example$getting_started/getting_started.sh[tag=stackablectl-install-operators]
----

The tool shows

[source]
----
include::example$getting_started/install_output.txt[]
----

TIP: Consult the xref:management:stackablectl:quickstart.adoc[] to learn more about how to use stackablectl.
For example, you can use the `--cluster kind` flag to create a Kubernetes cluster with link:https://kind.sigs.k8s.io/[kind].
--

Helm::
+
--
Add the Stackable Helm repository:
[source,bash]
----
include::example$getting_started/getting_started.sh[tag=helm-add-repo]
----

Install the Stackable Operators:
[source,bash]
----
include::example$getting_started/getting_started.sh[tag=helm-install-operators]
----

Helm will deploy the operators in a Kubernetes Deployment and apply the CRDs for the SparkApplication (as well as the CRDs for the required operators).
--
====

== What's next

xref:getting_started/first_steps.adoc[Execute a Spark Job] and
xref:getting_started/first_steps.adoc#_verify_that_it_works[verify that it works] by inspecting the pod logs.

=== Overview

The Stackable Spark-on-Kubernetes operator enables users to run Apache Spark workloads in a Kubernetes cluster easily by eliminating the requirement of having a local Spark installation. For this purpose, Stackble provides ready made Docker images with recent versions of Apache Spark and Python - for PySpark jobs - that provide the basis for running those workloads. Users of the Stackable Spark-on-Kubernetes operator can run their workloads on any recent Kubernetes cluster by applying a `SparkApplication` custom resource in which the job code, job dependencies, input and output data locations can be specified. The Stackable operator translates the user's `SparkApplication` manifest into a Kubernetes `Job` object and handles control to the Apache Spark scheduler for Kubernetes to construct the necessary driver and executor `Pods`.

image::spark-k8s.png[Job Flow]

When the job is finished, the `Pods` are terminated and the Kubernetes `Job` is completed.

The base images provided by Stackable contain only minimum of components to run Spark workloads. This is done mostly for performance and compatilbility reasons. Many Spark workloads build on top of third party libraries and frameworks and thus depend on additional packages that are not included in the Stackable images. This guide explains how users can provision their Spark jobs with additional dependencies.


=== Dependency provisioning

There are multiple ways to submit Apache Spark jobs with external dependencies. Each has it's own advantages and disadvantages and the choice of one over the other depends on existing technical and managerial constraints.

To provision job depencies in their workloads, users have to construct their `SparkApplication` with one of the following dependency specification:

- Hardened or encapsulated job images
- Condensed or lightweight job images
- Dependency volumes
- Spark native package coordinates and Python requirements

The following table provides a high level overview of the relevant aspects of each method.

|===
|Dependency specification |Job image size |Reproduciblity |Dev-op cost

|Encapsulated job images
|Large
|Guaranteed
|Medium to High

|Lightweight job images
|Small or Medium
|Not guaranteed
|Medium to High

|Dependency volumes
|Small
|Guaranteed
|Small to Medium

|Spark and Python packages
|Small
|Not guranteed
|Small
|===

==== Hardened or encapsulated job images

With this method, users submit a `SparkApplication` for which the `sparkImage` refers to a Docker image containing Apache Spark it's self, the job code and dependencies required by the job. It is recommended the users base their image on of Stakable images to ensure compatibility with the Stackable operator.

Since all packages required to run the Spark job are bundled in the image, the size of this image tends to get very large while at the same time guaranteeing reproducibility between submissions.

Example:

[source, yaml]
----
include::example$example-encapsulated.yaml[]
----
<1> Name of the encapsulated image.
<2> Name of the Spark job to run.

==== Condensed or lightweight job images

TODO

==== Dependency volumes

A `PersistentVolume` can be defined like this:

[source,yaml]
---
apiVersion: v1
kind: PersistentVolume
metadata:
  name: pv-ksv
spec:
  storageClassName: standard
  accessModes:
    - ReadWriteOnce
  capacity:
    storage: 2Gi
  hostPath:
    path: /host-location

i.e. it provides a link for Kubernetes between some storage external to kubernetes (in this case a path on the host; others are listed https://kubernetes.io/docs/concepts/storage/persistent-volumes/#types-of-persistent-volumes[here]) and a resource within the kubernetes cluster. This is done on a cluster basis: i.e. the PV is not tied to a pod or namespace.

The user of a pod then https://kubernetes.io/docs/tasks/configure-pod-container/configure-persistent-volume-storage/[defines] a `PersistenceVolumeClaim`: this is a request to use this storage, which **is** linked to a pod and thereby a namespace:

[source,yaml]
----
include::example$example-pvc.yaml[]
----
<1> Reference to a `PersistentVolume`, defining some cluster-reachable storage
<2> The name of the `PersistentVolumeClaim` that references the PV
<3> Defines a `Volume` backed by the PVC, local to the Custom Resource
<4> Defines the `VolumeMount` that is used by the Custom Resource

==== Spark native package coordinates and Python requirements

TODO

=== Persistent Volumes


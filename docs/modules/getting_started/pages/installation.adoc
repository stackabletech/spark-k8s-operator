= Installation

On this page you will install the Stackable Spark-on-Kubernetes Operator as well as the commons and secret Operators which are required by all Stackable Operators.

== Dependencies

The Spark-k8s Operator does not install a cluster or a set of nodes, but rather a SparkApplication that creates a spark-submit job, delegating this to the Spark driver, which in turn spins up executors for the duration of the job. Spark job dependencies can thus vary in their scope and detail. In this guide we are going to keep things simple and look at executing a Spark job that has a minimum of dependencies.

More information about the different ways to define Spark jobs and their dependencies is given on the following pages:

- xref:ROOT:usage.adoc[]
- xref:ROOT:job_dependencies.adoc[]

== Stackable Operators

There are 2 ways to install Stackable operators

1. Using xref:stackablectl::index.adoc[]

1. Using Helm

=== stackablectl

`stackablectl` is the command line tool to interact with Stackable operators and our recommended way to install Operators.
Follow the xref:stackablectl::installation.adoc[installation steps] for your platform.

After you have installed `stackablectl` run the following command to install the Spark-k8s operator:

[source,bash]
----
include::example$code/getting_started.sh[tag=stackablectl-install-operators]
----

The tool will show

----
[INFO ] Installing commons operator
[INFO ] Installing secret operator
[INFO ] Installing spark-k8s operator
----

TIP: Consult the xref:stackablectl::quickstart.adoc[] to learn more about how to use stackablectl. For example, you can use the `-k` flag to create a Kubernetes cluster with link:https://kind.sigs.k8s.io/[kind].

=== Helm

You can also use Helm to install the Operators. Add the Stackable Helm repository:
[source,bash]
----
include::example$code/getting_started.sh[tag=helm-add-repo]
----

Then install the Stackable Operators:
[source,bash]
----
include::example$code/getting_started.sh[tag=helm-install-operators]
----

Helm will deploy the Operators in a Kubernetes Deployment and apply the CRDs for the SparkApplication (as well as the CRDs for the required operators). You are now ready to create a Spark job in Kubernetes.

== What's next

xref:first_steps.adoc[Execute a Spark Job] and  xref:first_steps.adoc#_verify_that_it_works[verify that it works] by inspecting the pod logs.
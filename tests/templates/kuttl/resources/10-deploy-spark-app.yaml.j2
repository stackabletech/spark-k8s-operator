---
apiVersion: spark.stackable.tech/v1alpha1
kind: SparkApplication
metadata:
  name: resources-crd
spec:
  version: "1.0"
{% if lookup('env', 'VECTOR_AGGREGATOR') %}
  vectorAggregatorConfigMapName: vector-aggregator-discovery
{% endif %}
  sparkImage: "docker.stackable.tech/stackable/pyspark-k8s:{{ test_scenario['values']['spark'].split('-stackable')[0] }}-stackable{{ test_scenario['values']['spark'].split('-stackable')[1] }}"
  mode: cluster
  mainApplicationFile: local:///stackable/spark/examples/src/main/python/streaming/hdfs_wordcount.py
  args:
    - "/tmp2"
  sparkConf:
    spark.kubernetes.submission.waitAppCompletion: "false"
    spark.kubernetes.driver.pod.name: "resources-crd-driver"
    spark.kubernetes.executor.podNamePrefix: "resources-crd"
  job:
    logging:
      enableVectorAgent: {{ lookup('env', 'VECTOR_AGGREGATOR') | length > 0 }}
    resources:
      cpu:
        min: "100m"
        max: "200m"
      memory:
        limit: "1Gi"
  driver:
    logging:
      enableVectorAgent: {{ lookup('env', 'VECTOR_AGGREGATOR') | length > 0 }}
    resources:
      cpu:
        min: "1"
        max: "2"
      memory:
        limit: "1Gi"
  executor:
    instances: 1
    logging:
      enableVectorAgent: {{ lookup('env', 'VECTOR_AGGREGATOR') | length > 0 }}
    resources:
      cpu:
        min: "1500m"
        max: "3"
      memory:
        limit: "2Gi"
